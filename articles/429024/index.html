<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Creating GIF Animations with OpenCV</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="This tutorial will show you how to create animated GIF files using OpenCV, Python, and ImageMagick. Then combine these methods to create a meme genera...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="../../search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <a href="http://bit.ly/donateToWeeklyGeekly" class="donate-btn">DONATE</a>
  <section class="page js-page"><h1>Creating GIF Animations with OpenCV</h1><div class="post__text post__text-html js-mediator-article"><div style="text-align:center;"><img src="https://habrastorage.org/webt/g1/sx/hd/g1sxhdlqfra2bohbg5d7yjliv6g.gif"></div><br><br>  This tutorial will show you how to create animated GIF files using OpenCV, Python, and ImageMagick.  Then combine these methods to create a meme generator with OpenCV! <br><br>  We all need to laugh from time to time.  And perhaps the best way to find lulz is memes.  Some of my favorites: <br><br><ul><li>  Kermit the Frog: "But This Is Not My Business" </li><li>  Grumpy cat </li><li>  epic fail </li><li>  Good guy Greg </li></ul><br>  <b>But for me personally, none of these memes compare with the meme ‚ÄùDeal With It" ("Get over it" or "Understand it yourself"), an example of which is given at the beginning of the article.</b> <br><a name="habracut"></a><br>  It is usually used in the following cases: <br><br><ol><li>  As a response or objection to someone who does not approve of something you have done / said (‚ÄúGet over it‚Äù) </li><li>  Putting on glasses as if you were leaving and leaving a person alone with a problem (‚ÄúUnderstand yourself‚Äù) </li></ol><br>  A few years ago I was reading a funny article in an author's blog, which I can no longer remember how to generate such memes using computer vision.  Last week I could not find this guide anywhere, so as a blogger, computer vision expert and meme expert, I decided to write a tutorial myself!  (By the way, if you accidentally know the original source, please let me know so that I can express my gratitude to the author. <b>UPD:</b> Just found the original article from Kirk Kaiser‚Äôs blog, <a href="https://www.makeartwithpython.com/blog/deal-with-it-generator-face-recognition/">MakeArtWithPython</a> ). <br><br>  The development of the mec generator at OpenCV will teach us a number of valuable practical skills, including: <br><br><ol><li>  Face Detection with Deep Learning Techniques </li><li>  Use of the dlib library to locate face landmarks and extract eye areas </li><li>  How to calculate the angle of rotation between the eyes based on the information received </li><li>  And finally, how to generate animated GIFs using OpenCV (with a little using ImageMagick) </li></ol><br>  This guide should be fun and entertaining - and at the same time teach you the valuable computer vision programming skills that come in handy in the real world. <br><br><h1>  Creating gifs with OpenCV </h1><br>  In the first part of the guide, we will discuss the necessary conditions and dependencies for this project, including the correct setting of the development environment. <br><br>  Then we will look at the project / directory structure for our gif generator on OpenCV. <br><br>  As soon as we understand the structure of the project, we will consider: 1) our configuration file;  2) Python script responsible for creating GIF with OpenCV. <br><br>  Finally, we will evaluate the results of the work of the program on the popular meme ‚ÄúDeal With It‚Äù. <br><br><h4>  Prerequisites and dependencies </h4><br><img src="https://habrastorage.org/getpro/habr/post_images/ad6/c3e/193/ad6c3e193373bc04c877e60070d73071.png"><br>  <b>Fig.</b>  <b>1. To create gifs we will use OpenCV, dlib and ImageMagick</b> <br><br><h3>  Opencv and dlib </h3><br>  OpenCV is needed to identify faces in the frame and basic image processing.  Follow one of my <a href="https://www.pyimagesearch.com/opencv-tutorials-resources-guides/">OpenCV installation guides if OpenCV is</a> not installed on the system. <br><br>  Dlib is used to detect facial landmarks, which will allow us to find two eyes on the face and put on sunglasses over the top.  You can <a href="https://www.pyimagesearch.com/2018/01/22/install-dlib-easy-complete-guide/">install dlib using this instruction</a> . <br><br><h4>  Imagemagick </h4><br>  If you are not familiar with <a href="https://www.imagemagick.org/script/index.php">ImageMagick</a> , then in vain.  This is a cross platform command line tool with many image processing functions. <br><br>  Do you want to convert PNG / JPG to PDF with one command?  No problem. <br><br>  There are several images from which you need to make a multi-page PDF?  Easily. <br><br>  Need to draw polygons, lines and other shapes?  And it is possible. <br><br>  What about batch color adjustments or resizing of all pictures with one team?  To do this, you do not need to write a few lines in Python for OpenCV. <br><br>  ImageMagick also generates gifs from any images. <br><br>  To install ImageMagick on Ubuntu (or Raspbian), just use apt: <br><br>  Creating gifs with OpenCVShell <br><br><pre><code class="bash hljs">$ sudo apt-get install imagemagick</code> </pre> <br>  On macOS, you can use HomeBrew: <br><br><pre> <code class="bash hljs">$ brew install imagemagick</code> </pre> <br><h4>  imutils </h4><br>  In most articles, courses, and books, I use my handy package of image processing functions <a href="https://github.com/jrosebr1/imutils">imutils</a> .  It is installed in a system or virtual environment using pip: <br><br><pre> <code class="bash hljs">$ pip install imutils</code> </pre> <br><h2>  Project structure </h2><br><img src="https://habrastorage.org/getpro/habr/post_images/e42/281/af0/e42281af07fb94c9ae60a526098f662d.png"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">2. The project structure includes two directories, a configuration file and a Python script.</font></i> <br><br>  There are two directories in our project: <br><br><ul><li>  <code>images/</code> : examples of input images for which we want to make an animated GIF.  I found some images with me, but feel free to add my own. </li><li>  <code>assets/</code> : this folder contains our face detector, face face detector and all images + associated masks.  With these assets, we will overlay points and text on the original images from the first folder. </li></ul><br>  Due to the large number of customizable parameters, I decided to create a JSON configuration file, which: 1) makes editing parameters easier;  2) will require less command line arguments.  All configuration parameters required for this project are contained in <code>config.json</code> . <br><br>  Consider the contents of <code>config.json</code> and <code>create_gif.py</code> . <br><br><a name="1"></a>  <font color="gray">Note</font>  <font color="gray">Lane: Project code and 17-page manual on computer vision, machine learning and OpenCV are issued <a href="https://www.getdrip.com/forms/210393818/submissions">after registration</a> (mirror: <a href="https://dfiles.ru/files/6y2rosuo7">source code</a> , <a href="https://www.pyimagesearch.com/static/cv_dl_resource_guide.pdf">manual</a> ).</font> <br><br><h2>  GIF Generation with OpenCV </h2><br>  So, let's continue and start creating our OpenCV GIF generator! <br><br><h4>  The contents of the JSON configuration file </h4><br>  Let's start with the JSON configuration file, and then go to the Python script. <br><br>  Open a new <code>config.json</code> file and insert the following key / value pairs: <br><br>  Creating gifs with OpenCVPython <br><br><pre> <code class="python hljs">{ <span class="hljs-string"><span class="hljs-string">"face_detector_prototxt"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/deploy.prototxt"</span></span>, <span class="hljs-string"><span class="hljs-string">"face_detector_weights"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/res10_300x300_ssd_iter_140000.caffemodel"</span></span>, <span class="hljs-string"><span class="hljs-string">"landmark_predictor"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/shape_predictor_68_face_landmarks.dat"</span></span>,</code> </pre> <br>  These are the <a href="https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/">OpenCV face detector</a> model files <a href="https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/">for deep learning</a> . <br><br>  The last line is the path to the predictor dlib. <br><br>  And now we have some paths to the image files: <br><br><pre> <code class="python hljs"><span class="hljs-string"><span class="hljs-string">"sunglasses"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/sunglasses.png"</span></span>, <span class="hljs-string"><span class="hljs-string">"sunglasses_mask"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/sunglasses_mask.png"</span></span>, <span class="hljs-string"><span class="hljs-string">"deal_with_it"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/deal_with_it.png"</span></span>, <span class="hljs-string"><span class="hljs-string">"deal_with_it_mask"</span></span>: <span class="hljs-string"><span class="hljs-string">"assets/deal_with_it_mask.png"</span></span>,</code> </pre> <br>  These are the paths to our sunglasses, the text and the corresponding masks for them, which are shown below. <br><br>  First, fancy sunglasses and a mask: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c18/c4c/647/c18c4c6471e203aedea66a80c9080192.png"></div><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">3. You do not like glasses with pixels?</font></i>  <i><font color="gray">Just get over it</font></i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/58b/91a/d9c/58b91ad9c2e66238b3f3ac22fe1ee439.png"></div><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">4. You do not understand why you need a mask for sunglasses?</font></i>  <i><font color="gray">Just put up with it - or read the rest of the article to find out the answer.</font></i> <br><br>  And now our text is ‚ÄúDEAL WITH IT‚Äù and the mask: <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/ec3/4e4/923/ec34e4923e2d05a5b33c065de8f5af66.png"></div><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">5. Do you hate Helvetica Neue Condensed?</font></i>  <i><font color="gray">Deal with it</font></i> <br><br><div style="text-align:center;"><img src="https://habrastorage.org/getpro/habr/post_images/c6c/f70/819/c6cf708198bda68d849029b3ded02265.png"></div><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">6: This mask allows you to make a border around the text.</font></i>  <i><font color="gray">Oh, and maybe you do not need do not want a border?</font></i>  <i><font color="gray">Well, get over it</font></i> <br><br>  Masks are needed in order to superimpose the corresponding image on the photo: we'll deal with this later. <br><br>  Now let's set some parameters for the memes generator: <br><br><pre> <code class="python hljs"> <span class="hljs-string"><span class="hljs-string">"min_confidence"</span></span>: <span class="hljs-number"><span class="hljs-number">0.5</span></span>, <span class="hljs-string"><span class="hljs-string">"steps"</span></span>: <span class="hljs-number"><span class="hljs-number">20</span></span>, <span class="hljs-string"><span class="hljs-string">"delay"</span></span>: <span class="hljs-number"><span class="hljs-number">5</span></span>, <span class="hljs-string"><span class="hljs-string">"final_delay"</span></span>: <span class="hljs-number"><span class="hljs-number">250</span></span>, <span class="hljs-string"><span class="hljs-string">"loop"</span></span>: <span class="hljs-number"><span class="hljs-number">0</span></span>, <span class="hljs-string"><span class="hljs-string">"temp_dir"</span></span>: <span class="hljs-string"><span class="hljs-string">"temp"</span></span> }</code> </pre> <br>  Here are the definitions for each of the parameters: <br><br><ul><li>  <code>min_confidence</code> : minimum required face detection probability. </li><li>  <code>steps</code> : the number of frames in the final animation.  Each "step" moves the sunglasses from the top border down to the goal (i.e., to the eyes). </li><li>  <code>delay</code> : delay between frames in hundredths of a second. </li><li>  <code>final_delay</code> : the last frame delay in hundredths of a second (useful in this context, since we want the text to appear longer than the other frames). </li><li>  <code>loop</code> : a null value indicates that GIF repeats forever, otherwise specify a positive integer for the number of repetitions of the animation. </li><li>  <code>temp_dir</code> : the temporary directory in which each frame is stored will be before creating the final GIF. </li></ul><br><h4>  Memes, GIF and OpenCV </h4><br>  We have created a JSON configuration file, now let's move to the real code. <br><br>  Open a new file, name it <code>create_gif.py</code> and paste the following code: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># –∏–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –ø–∞–∫–µ—Ç–æ–≤ from imutils import face_utils from imutils import paths import numpy as np import argparse import imutils import shutil import json import dlib import cv2 import sys import os</span></span></code> </pre> <br>  Here we import the necessary packages.  In particular, we will use imutils, dlib and OpenCV.  To install these dependencies, see the ‚ÄúRequired Components and Dependencies‚Äù section above. <br><br>  Now the script has the necessary packages, so we define the <code>overlay_image</code> function: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">overlay_image</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(bg, fg, fgMask, coords)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–∞–∑–º–µ—Ä –ø–µ—Ä–µ–¥–Ω–µ–≥–æ –ø–ª–∞–Ω–∞ (—à–∏—Ä–∏–Ω–∞, –≤—ã—Å–æ—Ç–∞) –∏ # –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –µ–≥–æ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è (sH, sW) = fg.shape[:2] (x, y) = coords # –Ω–∞–ª–æ–∂–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ç–æ—á–Ω–æ —Ç–∞–∫–æ–π —à–∏—Ä–∏–Ω—ã –∏ –≤—ã—Å–æ—Ç—ã –∫–∞–∫ # –∏—Å—Ö–æ–¥–Ω–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∞, –Ω–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø—É—Å—Ç—ã–º, *–∫—Ä–æ–º–µ* –ø–µ—Ä–µ–¥–Ω–µ–≥–æ # –ø–ª–∞–Ω–∞, –∫–æ—Ç–æ—Ä—ã–π –º—ã –¥–æ–±–∞–≤–ª—è–µ–º overlay = np.zeros(bg.shape, dtype="uint8") overlay[y:y + sH, x:x + sW] = fg # –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç, *–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã* –∏ *—Å—Ç–µ–ø–µ–Ω—å* # –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏, –µ–≥–æ —Ä–∞–∑–º–µ—Ä—ã —Ç–∞–∫–∏–µ –∂–µ, –∫–∞–∫ —É –∏—Å—Ö–æ–¥–Ω–æ–≥–æ # –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –Ω–æ –æ–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –º–∞—Å–∫—É –Ω–∞–ª–æ–∂–µ–Ω–∏—è alpha = np.zeros(bg.shape[:2], dtype="uint8") alpha[y:y + sH, x:x + sW] = fgMask alpha = np.dstack([alpha] * 3) # –≤—ã–ø–æ–ª–Ω—è–µ–º –∞–ª—å—Ñ–∞-—Å–º–µ—à–∏–≤–∞–Ω–∏–µ –¥–ª—è –ø–µ—Ä–µ–¥–Ω–µ–≥–æ –ø–ª–∞–Ω–∞, # —Ñ–æ–Ω–∞ –∏ –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–∞ output = alpha_blend(overlay, bg, alpha) # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç return output</span></span></code> </pre> <br>  The <code>overlay_image</code> function superimposes the foreground ( <code>fg</code> ) on the upper part of the background image ( <code>bg</code> ) on the coordinates <code>coords</code> (coordinates <i>(x, y)</i> ), implementing alpha transparency on the foreground mask <code>fgMask</code> . <br><br>  To familiarize yourself with the basics of OpenCV, such as working with masks, do not forget to read <a href="https://www.pyimagesearch.com/2018/07/19/opencv-tutorial-a-guide-to-learn-opencv/">this manual</a> . <br><br>  To complete the blending process, perform alpha blending: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">alpha_blend</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(fg, bg, alpha)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ñ–æ–Ω, –ø–µ—Ä–µ–¥–Ω–∏–π –ø–ª–∞–Ω –∏ –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª # –≤ —á–∏—Å–ª–∞ —Å –ø–ª–∞–≤–∞—é—â–µ–π –∑–∞–ø—è—Ç–æ–π –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 1] fg = fg.astype("float") bg = bg.astype("float") alpha = alpha.astype("float") / 255 # –≤—ã–ø–æ–ª–Ω—è–µ–º –∞–ª—å—Ñ–∞-—Å–º–µ—à–∏–≤–∞–Ω–∏–µ fg = cv2.multiply(alpha, fg) bg = cv2.multiply(1 - alpha, bg) # –¥–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–¥–Ω–∏–π –ø–ª–∞–Ω –∏ —Ñ–æ–Ω, –ø–æ–ª—É—á–∞—è –∫–æ–Ω–µ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç output = cv2.add(fg, bg) # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç return output.astype("uint8")</span></span></code> </pre> <br>  This implementation of alpha blending is also provided <a href="https://www.learnopencv.com/alpha-blending-using-opencv-cpp-python/">on the LearnOpenCV blog</a> . <br><br>  In essence, we convert the foreground, background, and alpha channel into floating point numbers in the range <i>[0, 1]</i> .  Then we perform alpha blending, add foreground and background to get the result, which we return to the calling function. <br><br>  We will also create a helper function that allows generating GIFs from a set of image paths using ImageMagick and the <code>convert</code> command: <br><br><pre> <code class="python hljs"><span class="hljs-function"><span class="hljs-keyword"><span class="hljs-function"><span class="hljs-keyword">def</span></span></span><span class="hljs-function"> </span><span class="hljs-title"><span class="hljs-function"><span class="hljs-title">create_gif</span></span></span><span class="hljs-params"><span class="hljs-function"><span class="hljs-params">(inputPath, outputPath, delay, finalDelay, loop)</span></span></span><span class="hljs-function">:</span></span> <span class="hljs-comment"><span class="hljs-comment"># –ø–æ–ª—É—á–∏—Ç—å –≤—Å–µ –ø—É—Ç–∏ –∏–∑ –ø–∞–ø–∫–∏ –∏—Å—Ö–æ–¥–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π imagePaths = sorted(list(paths.list_images(inputPath))) # —É–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø—É—Ç—å –≤ —Å–ø–∏—Å–∫–µ lastPath = imagePaths[-1] imagePaths = imagePaths[:-1] # —Å–∫–æ–Ω—Å—Ç—Ä—É–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–∞–Ω–¥—É imagemagick 'convert' –¥–ª—è # –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ GIF —Å –±–æ–ª–µ–µ –¥–ª–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–¥–µ—Ä–∂–∫–æ–π –¥–ª—è # –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞ (–µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ) cmd = "convert -delay {} {} -delay {} {} -loop {} {}".format( delay, " ".join(imagePaths), finalDelay, lastPath, loop, outputPath) os.system(cmd)</span></span></code> </pre> <br>  The <code>create_gif</code> function takes a set of images and assembles them into a GIF animation with a specified delay between frames and loops.  All this handles ImageMagick ‚Äî we simply wrap the <code>convert</code> command in a function that dynamically processes various parameters. <br><br>  See the <a href="https://imagemagick.org/script/convert.php">documentation</a> for available <code>convert</code> arguments.  There you will see how many features this command has! <br><br>  Specifically, in this function, we: <br><br><ul><li>  We take <code>imagePaths</code> . </li><li>  Select the path of the last image, which will be a separate delay. </li><li>  Reassign <code>imagePaths</code> to eliminate the last path. </li><li>  We put together a command with command line arguments, and then instruct the operating system to <code>convert</code> to create a GIF animation. </li></ul><br>  Assign the script own command line arguments: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># —Å–æ–æ—Ä—É–∂–∞–µ–º –ø–∞—Ä—Å–µ—Ä –∏ —Ä–∞–∑–±–∏—Ä–∞–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã ap = argparse.ArgumentParser() ap.add_argument("-c", "--config", required=True, help="path to configuration file") ap.add_argument("-i", "--image", required=True, help="path to input image") ap.add_argument("-o", "--output", required=True, help="path to output GIF") args = vars(ap.parse_args())</span></span></code> </pre> <br>  We have three command line arguments that are processed at runtime: <br><br><ul><li>  <code>--config</code> : path to the JSON configuration file.  We covered the configuration file in the previous section. </li><li>  <code>--image</code> : path to the input image, against which the animation is created (ie, face detection, adding sunglasses, and then text). </li><li>  <code>--output</code> : the path to the final GIF. </li></ul><br>  Each of these arguments is required when running the script on the command line / terminal. <br><br>  Load the configuration file, as well as the glasses and the corresponding mask: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># –∑–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª JSON, # –æ—á–∫–∏ –∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –º–∞—Å–∫—É config = json.loads(open(args["config"]).read()) sg = cv2.imread(config["sunglasses"]) sgMask = cv2.imread(config["sunglasses_mask"]) # —É–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É (–µ—Å–ª–∏ –æ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç), –∞ –∑–∞—Ç–µ–º # —Å–æ–∑–¥–∞—ë–º –Ω–æ–≤—É—é, –ø—É—Å—Ç—É—é –ø–∞–ø–∫—É, –≥–¥–µ –±—É–¥–µ–º —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–∞–∂–¥—ã–π # –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–∞–¥—Ä GIF-–∞–Ω–∏–º–∞—Ü–∏–∏ shutil.rmtree(config["temp_dir"], ignore_errors=True) os.makedirs(config["temp_dir"])</span></span></code> </pre> <br>  Here we load the configuration file (which in the future may be available as a Python dictionary).  Then we load sunglasses and a mask. <br><br>  If something remains from the previous script, delete the temporary directory, and then re-create an empty temporary directory.  The temporary folder will contain each individual frame from the GIF animation. <br><br>  Now we‚Äôll load the <a href="https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/">OpenCV deep learning face detector</a> into memory: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># load our OpenCV face detector and dlib facial landmark predictor print("[INFO] loading models...") detector = cv2.dnn.readNetFromCaffe(config["face_detector_prototxt"], config["face_detector_weights"]) predictor = dlib.shape_predictor(config["landmark_predictor"])</span></span></code> </pre> <br>  To do this, call <code>cv2.dnn.readNetFromCaffe</code> .  The <code>dnn</code> module is available only in OpenCV 3.3 or later.  The face detector will detect the presence of faces in the image: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/a91/d3a/0cd/a91d3a0cde3dcb3cac9799c823e47c8c.jpg"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">7. Face Detector Operation Using OpenCV DNN</font></i> <br><br>  Then load the <a href="https://www.pyimagesearch.com/2017/04/03/facial-landmarks-dlib-opencv-python/">dlib face predictor</a> .  It will allow you to localize individual structures: eyes, eyebrows, nose, mouth and chin line: <br><br><img src="https://habrastorage.org/getpro/habr/post_images/056/816/890/0568168909b7f01d2f70f6e58faa9ed9.jpg"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">8. On my face there are landmarks found by dlib</font></i> <br><br>  Later in this script we extract only the eye area. <br><br>  Moving on, let's find the face: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># –∑–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ —Å–æ–∑–¥–∞—ë–º –±–ª–æ–± image = cv2.imread(args["image"]) (H, W) = image.shape[:2] blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0)) # –ø–µ—Ä–µ–¥–∞—ë–º –±–ª–æ–± –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –∏ –ø–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã print("[INFO] computing object detections...") detector.setInput(blob) detections = detector.forward() # –¥–ª—è –Ω–∞–ª–æ–∂–µ–Ω–∏—è –æ—á–∫–æ–≤ –Ω—É–∂–Ω–æ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ –ª–∏—Ü–æ, –ø–æ—ç—Ç–æ–º—É # –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ª–∏—Ü–æ, –¥–ª—è –∫–æ—Ç–æ—Ä–æ–≥–æ –≤—ã–¥–∞—ë—Ç—Å—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å i = np.argmax(detections[0, 0, :, 2]) confidence = detections[0, 0, i, 2] # –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ–º —Å–ª–∞–±—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã if confidence &lt; config["min_confidence"]: print("[INFO] no reliable faces found") sys.exit(0)</span></span></code> </pre> <br>  In this block we do the following: <br><br><ul><li>  Load the original <code>image</code> . </li><li>  We construct a <code>blob</code> for sending to the neural network face detector.  <a href="https://www.pyimagesearch.com/2017/11/06/deep-learning-opencvs-blobfromimage-works/">This article</a> describes how <code>blobFromImage</code> from OpenCV works. </li><li>  Perform face detection procedure. </li><li>  We find the person with the highest probability value and compare it with the minimum acceptable threshold.  If the criteria are not met, simply exit the script.  Otherwise, continue. </li></ul><br>  Now we will extract the face and calculate the reference points: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># –≤—ã—á–∏—Å–ª—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (x, y) –æ–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—å–Ω–æ–π # —Ä–∞–º–∫–∏ –Ω–∞ –ª–∏—Ü–µ box = detections[0, 0, i, 3:7] * np.array([W, H, W, H]) (startX, startY, endX, endY) = box.astype("int") # –∫–æ–Ω—Å—Ç—Ä—É–∏—Ä—É–µ–º –ø—Ä—è–º–æ—É–≥–æ–ª—å–Ω—ã–π –æ–±—ä–µ–∫—Ç dlib –∏–∑ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –æ–≥—Ä–∞–Ω–∏—á–∏—Ç–µ–ª—å–Ω–æ–π # —Ä–∞–º–∫–∏ –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Ä–∏–µ–Ω—Ç–∏—Ä—ã –≤–Ω—É—Ç—Ä–∏ –Ω–µ–≥–æ rect = dlib.rectangle(int(startX), int(startY), int(endX), int(endY)) shape = predictor(image, rect) shape = face_utils.shape_to_np(shape) # –±–µ—Ä—ë–º –∏–Ω–¥–µ–∫—Å—ã –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤ –¥–ª—è –ª–µ–≤–æ–≥–æ –∏ –ø—Ä–∞–≤–æ–≥–æ –≥–ª–∞–∑, –∑–∞—Ç–µ–º # –≤—ã—á–∏—Å–ª—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–∞–∂–¥–æ–≥–æ –≥–ª–∞–∑–∞ (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS["left_eye"] (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS["right_eye"] leftEyePts = shape[lStart:lEnd] rightEyePts = shape[rStart:rEnd]</span></span></code> </pre> <br>  To extract the face and find the facial references, we do the following: <br><br><ul><li>  Retrieve the coordinates of the bounding box around the face. </li><li>  We create a <code>rectangle</code> object in dlib and apply face localization. </li><li>  Extract the <i>(x, y)</i> coordinates of the <code>leftEyePts</code> and <code>rightEyePts</code> , respectively. </li></ul><br>  Given the coordinates of the eyes, you can calculate where and how to place sunglasses: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># –≤—ã—á–∏—Å–ª—è–µ–º —Ü–µ–Ω—Ç—Ä –º–∞—Å—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≥–ª–∞–∑–∞ leftEyeCenter = leftEyePts.mean(axis=0).astype("int") rightEyeCenter = rightEyePts.mean(axis=0).astype("int") # –≤—ã—á–∏—Å–ª—è–µ–º —É–≥–æ–ª –º–µ–∂–¥—É —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞–º–∏ –≥–ª–∞–∑ dY = rightEyeCenter[1] - leftEyeCenter[1] dX = rightEyeCenter[0] - leftEyeCenter[0] angle = np.degrees(np.arctan2(dY, dX)) - 180 # –ø–æ–≤–æ—Ä–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—á–∫–æ–≤ –Ω–∞ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–π —É–≥–æ–ª, —á—Ç–æ–±—ã # –ø–æ–≤–æ—Ä–æ—Ç –æ—á–∫–æ–≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª –Ω–∞–∫–ª–æ–Ω—É –≥–æ–ª–æ–≤—ã sg = imutils.rotate_bound(sg, angle) # –æ—á–∫–∏ –Ω–µ –¥–æ–ª–∂–Ω—ã –ø–æ–∫—Ä—ã–≤–∞—Ç—å *–≤—Å—é* —à–∏—Ä–∏–Ω—É –ª–∏—Ü–∞, –∞ –≤ –∏–¥–µ–∞–ª–µ # —Ç–æ–ª—å–∫–æ –≥–ª–∞–∑–∞ ‚Äî –∑–¥–µ—Å—å –≤—ã–ø–æ–ª–Ω—è–µ–º –ø—Ä–∏–º–µ—Ä–Ω—É—é –æ—Ü–µ–Ω–∫—É –∏ —É–∫–∞–∑—ã–≤–∞–µ–º # 90% —à–∏—Ä–∏–Ω—ã –ª–∏—Ü–∞ –≤ –∫–∞—á–µ—Å—Ç–≤–µ —à–∏—Ä–∏–Ω—ã –æ—á–∫–æ–≤ sgW = int((endX - startX) * 0.9) sg = imutils.resize(sg, width=sgW) # –≤ –æ—á–∫–∞—Ö –µ—Å—Ç—å –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–µ —á–∞—Å—Ç–∏ (–Ω–∏–∂–Ω—è—è —á–∞—Å—Ç—å, –ø–æ–¥ –ª–∏–Ω–∑–∞–º–∏ # –∏ –Ω–æ—Å–æ–º), –ø–æ—ç—Ç–æ–º—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–∏–µ–º–ª–µ–º–æ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ # –Ω—É–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –º–∞—Å–∫—É –∏ –∞–ª—å—Ñ–∞-—Å–º–µ—à–∏–≤–∞–Ω–∏–µ ‚Äî –∑–¥–µ—Å—å –º—ã # –≤—ã–ø–æ–ª–Ω—è–µ–º –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—é –º–∞—Å–∫–∏ —Å —Ç–æ–π –∂–µ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π, # –∫–∞–∫ —É –æ—á–∫–æ–≤ –≤—ã—à–µ sgMask = cv2.cvtColor(sgMask, cv2.COLOR_BGR2GRAY) sgMask = cv2.threshold(sgMask, 0, 255, cv2.THRESH_BINARY)[1] sgMask = imutils.rotate_bound(sgMask, angle) sgMask = imutils.resize(sgMask, width=sgW, inter=cv2.INTER_NEAREST)</span></span></code> </pre> <br>  First, we calculate the center of each eye, then the angle between the centroids.  The same operation is performed with horizontal <a href="https://www.pyimagesearch.com/2017/05/22/face-alignment-with-opencv-and-python/">alignment of the face in the frame</a> . <br><br>  Now you can rotate and resize points.  Please note that we use <a href="https://www.pyimagesearch.com/2017/01/02/rotate-images-correctly-with-opencv-and-python/">the rotate_bound function</a> , and not just <code>rotate</code> , so that OpenCV will not cut off parts that are not visible after affine transformation. <br><br>  The same operations that were applied to the glasses, apply to the mask.  But first you need to convert it to shades of gray and binarize, because the masks are always binary.  Then we rotate and resize the mask in the same way as we did with the glasses. <br><br>  <i><b>Note:</b> Please note that when changing the size of the mask, we use interpolation on the nearest neighboring points, because the mask must have only two values ‚Äã‚Äã(0 and 255).</i>  <i>Other interpolation methods are more aesthetic, but not suitable for masks.</i>  <i><a href="https://www.cambridgeincolour.com/tutorials/image-interpolation.htm">Here</a> you can get additional information about interpolation by the nearest neighboring points.</i> <br><br>  The remaining three blocks of code create frames for GIF animation: <br><br><pre> <code class="python hljs"><span class="hljs-comment"><span class="hljs-comment"># –æ—á–∫–∏ –ø–∞–¥–∞—é—Ç —Å–≤–µ—Ä—Ö—É –∫–∞–¥—Ä–∞, —Ç–∞–∫ —á—Ç–æ # –æ–ø—Ä–µ–¥–µ–ª—è–µ–º N —Ä–∞–≤–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –≤–µ—Ä—Ö–Ω–∏–º –∫—Ä–∞–µ–º –∫–∞–¥—Ä–∞ # –∏ –∫–æ–Ω–µ—á–Ω—ã–º –ø–æ–ª–æ–∂–µ–Ω–∏–µ–º steps = np.linspace(0, rightEyeCenter[1], config["steps"], dtype="int") # start looping over the steps for (i, y) in enumerate(steps): # –≤—ã—á–∏—Å–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ–±–æ–ª—å—à–æ–≥–æ —Å–º–µ—â–µ–Ω–∏—è –≤–ª–µ–≤–æ # –∏ –≤–≤–µ—Ä—Ö, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ—á–∫–∏ *–Ω–∞—á–∏–Ω–∞—é—Ç—Å—è* –Ω–µ –ø—Ä—è–º–æ –≤ # —Ü–µ–Ω—Ç—Ä–µ –≥–ª–∞–∑–∞, –∞ —ç—Ç–æ —Å–º–µ—â–µ–Ω–∏–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–∫—Ä—ã—Ç—å –≤—Å—é # –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –ø–ª–æ—â–∞–¥—å shiftX = int(sg.shape[1] * 0.25) shiftY = int(sg.shape[0] * 0.35) y = max(0, y - shiftY) # add the sunglasses to the image output = overlay_image(image, sg, sgMask, (rightEyeCenter[0] - shiftX, y))</span></span></code> </pre> <br>  Points fall from the top of the image.  On each frame, they are displayed closer to the face until they cover their eyes.  Using the <code>"steps"</code> variable in the JSON configuration file, we generate y-coordinates for each frame.  To do this, effortlessly use the function <code>linspace</code> from NumPy. <br><br>  The lines with a slight shift to the left and up may seem a bit strange, but they are needed to ensure that the glasses cover the eyes entirely, rather than just moving to the point where the center of the eye is located.  I empirically determined the percentage values ‚Äã‚Äãto calculate the shift on each axis.  The next line provides no negative values. <br><br>  Using the <code>overlay_image</code> function, <code>overlay_image</code> generate the final <code>output</code> frame. <br><br>  Now apply the text ‚ÄúDEAL WITH IT‚Äù using another mask: <br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment"># –µ—Å–ª–∏ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–≥, —Ç–æ —Ç–µ–ø–µ—Ä—å –¥–æ–±–∞–≤–ª—è–µ–º # —Ç–µ–∫—Å—Ç "DEAL WITH IT" –≤–Ω–∏–∑—É –∫–∞–¥—Ä–∞ if i == len(steps) - 1: # –∑–∞–≥—Ä—É–∂–∞–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É "DEAL WITH IT" –∏ –º–∞—Å–∫—É, # –ø—Ä–æ–≤–µ—Ä—è–µ–º –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—é dwi = cv2.imread(config["deal_with_it"]) dwiMask = cv2.imread(config["deal_with_it_mask"]) dwiMask = cv2.cvtColor(dwiMask, cv2.COLOR_BGR2GRAY) dwiMask = cv2.threshold(dwiMask, 0, 255, cv2.THRESH_BINARY)[1] # –∏–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞ –∏ –º–∞—Å–∫–∏ –Ω–∞ 80% —à–∏—Ä–∏–Ω—ã –∫–æ–Ω–µ—á–Ω–æ–≥–æ # –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è oW = int(W * 0.8) dwi = imutils.resize(dwi, width=oW) dwiMask = imutils.resize(dwiMask, width=oW, inter=cv2.INTER_NEAREST) # –≤—ã—á–∏—Å–ª—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã, –≥–¥–µ —Ä–∞–∑–º–µ—â–∞—Ç—å —Ç–µ–∫—Å—Ç, –∏ # –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ oX = int(W * 0.1) oY = int(H * 0.8) output = overlay_image(output, dwi, dwiMask, (oX, oY))</span></span></code> </pre> <br>  At the last step we superimpose the text, which in reality is another image. <br><br>  I decided to use an image because the rendering capabilities of OpenCV fonts are rather limited.  In addition, I wanted to add a shadow and border around the text, which, again, OpenCV does not know how. <br><br>  In the rest of this code, we load both the image and the mask, and then perform alpha blending to generate the final result. <br><br>  It remains only to save each frame to disk and then create a GIF animation: <br><br><pre> <code class="python hljs"> <span class="hljs-comment"><span class="hljs-comment"># –∑–∞–ø–∏—Å–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É p = os.path.sep.join([config["temp_dir"], "{}.jpg".format( str(i).zfill(8))]) cv2.imwrite(p, output) # –≤—Å–µ —Ñ–∞–π–ª—ã —É–∂–µ –∑–∞–ø–∏—Å–∞–Ω—ã –Ω–∞ –¥–∏—Å–∫, —Ç–∞–∫ —á—Ç–æ –º–æ–∂–Ω–æ –ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å # –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ GIF-–∞–Ω–∏–º–∞—Ü–∏–∏ print("[INFO] creating GIF...") create_gif(config["temp_dir"], args["output"], config["delay"], config["final_delay"], config["loop"]) # –æ—á–∏—Å—Ç–∫–∞ -- —É–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É print("[INFO] cleaning up...") shutil.rmtree(config["temp_dir"], ignore_errors=True)</span></span></code> </pre> <br>  Write the result to disk.  After generating all frames, call the function <code>create_gif</code> to create a GIF-animation file.  Remember, this is a shell that passes parameters to the ImageMagick <code>convert</code> command line tool. <br><br>  Finally, delete the temporary output directory and the individual image files. <br><br><h2>  results </h2><br>  Now the most interesting: let's see what our meme generator has created! <br><br>  Be sure to <a href="https://habr.com/ru/post/429024/">download the</a> source code, sample images, and deep learning models.  Then open a terminal and execute the following command: <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/adrian.jpg \ --output adrian_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/dca/b24/46e/dcab2446ec5dc96065e37a473375eea6.gif"><br>  <i><font color="gray">Figure 9. GIF animation generated with OpenCV and ImageMagick with this Python script</font></i> <br><br>  Here you can see a GIF created using OpenCV and ImageMagick.  The following actions are performed on it: <br><br><ol><li>  The correct detection of my face. </li><li>  Localization of the eyes and the calculation of their centers. </li><li>  Points correctly fall on the face. </li></ol><br>  Readers of my blog know that I am a big nerd in the "Jurassic Park" and often mention it in my books, courses and textbooks. <br><br>  Do not like the <i>"Jurassic Park"</i> ? <br><br>  Well, here is my answer: <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/adrian_jp.jpg \ --output adrian_jp_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/da9/0d7/740/da90d7740e8ac813b9f99a727b9e04bc.gif"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">10. GIF-animation of OpenCV based on a photo from a recent screening of the film ‚ÄúJurassic World 2‚Äù</font></i> <br><br>  Here I am at the show ‚ÄúThe World of the Jurassic Period: 2‚Äù in a thematic T-shirt, with a glass of light and collection book. <br><br>  A funny story: <br><br>  Five or six years ago, my wife and I visited the Epcot Center theme park in Walt Disney World, Florida. <br><br>  We decided to go on a journey to get away from the harsh winter in Connecticut, and desperately needed sunlight. <br><br>  Unfortunately, it rained all the time in Florida, and the temperature barely exceeded 10 ¬∞ C. <br><br>  Near the Canadian Gardens, Trisha took a picture of me: she says that I look like a vampire with pale skin, dark clothes and a hood, against the background of lush gardens behind: <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/vampire.jpg \ --output vampire_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/ad1/1ce/ca2/ad11ceca2ed48792a5aa28c0c8dc7f40.gif"><br>  <i><font color="gray">Fig.</font></i>  <i><font color="gray">11. With OpenCV and Python, you can make this meme or other animated GIF</font></i> <br><br>  That evening, Trisha published a photo in social networks - I had to put up with it. <br><br>  Those of you who attended PyImageConf 2018 ( <a href="https://www.pyimagesearch.com/2018/10/01/pyimageconf-2018-recap/">read the review</a> ) know that I am always open for jokes.  For example: <br><br>  <i>Question: Why does the rooster cross the road?</i> <br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/rooster.jpg \ --output rooster_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/5dd/e92/ef0/5dde92ef04cb35436e87b0b70cc5926d.gif"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. </font><font style="vertical-align: inherit;">12. The face is recognized even with low contrast, and OpenCV correctly processes the photo and lowers the sunglasses.</font></font></font></i> <br><br> <i><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Answer: I will not say the answer - put up with it. </font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Finally, we conclude today's guide with a good meme. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">About six years ago, my father and I adopted a little beagle, Gemma. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Here you can see Gemma on my shoulder:</font></font><br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/pupper.jpg \ --output pupper_out.gif [INFO] loading models... [INFO] computing object detections... [INFO] creating GIF... [INFO] cleaning up...</code> </pre> <br><img src="https://habrastorage.org/getpro/habr/post_images/08a/b5a/728/08ab5a728e8bd48ac2550a2962e76165.gif"><br> <i><font color="gray"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Fig. </font><font style="vertical-align: inherit;">13. Gemma is amazing. </font><font style="vertical-align: inherit;">Do not you think so? </font><font style="vertical-align: inherit;">Then ‚Äúput up with it‚Äù! </font></font></font></i> <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Do not agree that she is cute? </font><font style="vertical-align: inherit;">Get over it.</font></font><br><br><h4><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> An AttributeError error occurred? </font></font></h4><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Do not worry! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If you see this error:</font></font><br><br><pre> <code class="bash hljs">$ python create_gif.py --config config.json --image images/adrian.jpg \ --output adrian_out.gif ... Traceback (most recent call last): File <span class="hljs-string"><span class="hljs-string">"create_gif.py"</span></span>, line 142, <span class="hljs-keyword"><span class="hljs-keyword">in</span></span> &lt;module&gt; (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[<span class="hljs-string"><span class="hljs-string">"left_eye"</span></span>] AttributeError: module <span class="hljs-string"><span class="hljs-string">'imutils.face_utils'</span></span> has no attribute <span class="hljs-string"><span class="hljs-string">'FACIAL_LANDMARKS_IDXS'</span></span></code> </pre> <br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> ... then you just need to update the imutils package: </font></font><br><br><pre> <code class="bash hljs">$ pip install --upgrade imutils Collecting imutils ... Successfully installed imutils-0.5.1</code> </pre> <br>  Why? <br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">By default, it </font></font><code>imutils.face_utils</code><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">uses the 68-point detector of landmarks, built-in to dlib (as in this article). </font><font style="vertical-align: inherit;">There is </font></font><a href="https://www.pyimagesearch.com/2018/04/02/faster-facial-landmark-detector-with-dlib/"><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">a faster 5-point detector</font></font></a><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> , which now also works with imutils. </font><font style="vertical-align: inherit;">I recently updated imutils to support both detectors (so you may see an error).</font></font><br><br><h1>  Summary </h1><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In today's tutorial, you learned how to create a GIF using OpenCV. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">To make the lesson fun, we used OpenCV to generate GIF-animation ‚ÄúDeal With It‚Äù, a popular meme (and my favorite), which in one form or another is found on almost every social networking site. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">In the process, we used computer vision and deep learning to solve several practical problems:</font></font><br><br><ul><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Definition of persons </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Prediction of landmarks </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Determining areas of the face (in this case, the eye) </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Calculating the angle between the eyes to align the face </font></font></li><li><font style="vertical-align: inherit;"><font style="vertical-align: inherit;"> Creating transparent overlays using alpha blending </font></font></li></ul><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Finally, we took a set of generated images and created an animated GIF using OpenCV and ImageMagick. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">I hope you enjoyed today's lesson! </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">If you like it, please leave a comment and let me know. </font></font><br><br><font style="vertical-align: inherit;"><font style="vertical-align: inherit;">Well, if you do not like it, it does not matter, just accept this.</font></font> ;) </div><p>Source: <a href="https://habr.com/ru/post/429024/">https://habr.com/ru/post/429024/</a></p>
<section class="navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><p>Waiting for the list form <a href="../../index.html">here</a>...</p></nav>
</section>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>
</body>

</html>