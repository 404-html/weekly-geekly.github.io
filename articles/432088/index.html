<!doctype html>
<html class="no-js" lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-134931760-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-134931760-1');
  </script>

  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>MySQL High Availability on GitHub</title>
  <link rel="icon" type="image/x-icon" href="/favicon.ico" />
  <meta name="description" content="GitHub uses MySQL as the main data repository for everything that is not related to git , so the availability of MySQL is key to the normal operation ...">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="../../css/main.css">

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script>window.jQuery || document.write('<script src="../../js/vendors/jquery-3.3.1.min.js"><\/script>')</script>
</head>

<body>
  <!--[if lte IE 9]>
    <p class="browserupgrade">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience and security.</p>
  <![endif]-->
  <nav class="page-headings-container js-page-headings-container"></nav>
  <div class="tools-bar js-tools-bar">
    <!-- <a href="https://quick-geek.github.io/search.html" title="Search">üîé</a> -->
    <a class="js-list-of-headings-button" data-state="closed" href="#" title="Headings">üìú</a>
    <a class="js-go-to-top-button" href="#" title="Go to Top">‚¨ÜÔ∏è</a>
    <a class="js-go-to-bottom-button" href="#" title="Go to Bottom">‚¨áÔ∏è</a>
  </div>
  <section class="page js-page"><h1>MySQL High Availability on GitHub</h1><div class="post__text post__text-html js-mediator-article"><p> GitHub uses MySQL as the main data repository for everything that is not related to <code>git</code> , so the availability of MySQL is key to the normal operation of GitHub.  The site itself, the GitHub API, the authentication system and many other features require access to databases.  We use several MySQL clusters to handle various services and tasks.  They are set up according to the classical scheme with one <em>main</em> node available for recording and its replicas.  <em>Replicas</em> (the remaining nodes of the cluster) asynchronously reproduce the changes of the main node and provide read access. </p><br><p>  The availability of the main nodes is critical.  Without a master node, the cluster does not support writing, which means that the necessary changes cannot be saved.  Committing transactions, registering problems, creating new users, repositories, reviews and much more will be simply impossible. </p><br><p>  To maintain the record, you need the corresponding available node ‚Äî the main node in the cluster.  However, no less important is the ability to identify or <em>detect</em> such a node. </p><br><p>  In the event of a failure of the current main node, it is important to ensure the prompt appearance of a new replacement server, as well as to be able to quickly notify all services about this change.  Total downtime is the sum of the time it takes to detect a crash, fail over, and notify about a new main node. </p><br><p><img src="https://habrastorage.org/webt/m8/ah/po/m8ahpo0jhrucgwj3kb5u7hn9edo.jpeg"></p><a name="habracut"></a><br><p>  This publication describes a solution for ensuring high availability of MySQL on GitHub and detection of the main service, which allows us to reliably perform operations across several data centers, maintain operability when certain such centers are unavailable, and guarantee minimum downtime in case of failure. </p><br><h3 id="celi-obespecheniya-vysokoy-dostupnosti">  Goals for High Availability </h3><br><p>  The solution described in the article is a new, improved version of previous solutions for providing high availability (HA) implemented in GitHub.  As we grow, we need to adapt the MySQL HA strategy to change.  We aim to follow similar approaches for MySQL and other services on GitHub. </p><br><p>  To find the right solution for high availability and service discovery, you must first answer a few specific questions.  Here is their sample list: </p><br><ul><li>  What is the maximum downtime for you uncritically? </li><li>  How reliable are crash detection tools?  Are false positives (premature failover) critical for you? </li><li>  How reliable is the failover system?  Where can fail occur? </li><li>  How efficiently does the solution work in multiple data center environments?  How effective is the solution in low and high latency networks? </li><li>  Will the solution continue to operate in the event of a complete failure of the data processing center (DPC) or in network isolation conditions? </li><li>  What mechanism (if any) prevents or mitigates the effects of the emergence of two main servers in a cluster that independently write to each other? </li><li>  Is data loss critical for you?  If so, to what extent? </li></ul><br><p>  In order to demonstrate, let's first consider the previous solution and discuss why we decided to refuse it. </p><br><h3 id="otkaz-ot-ispolzovaniya-vip-i-dns-dlya-obnaruzheniya">  Refusal to use VIP and DNS for detection </h3><br><p>  As part of the previous decision, we used: </p><br><ul><li>  <a href="https://githubengineering.com/orchestrator-github/">orchestrator</a> for detecting and failing; </li><li>  VIP and DNS to locate the main node. </li></ul><br><p>  In this case, the clients detected the entry node by its name, for example, <code>mysql-writer-1.github.net</code> .  By name, the virtual IP address (VIP) of the host has been determined. </p><br><p>  Thus, in the normal situation, the clients simply had to resolve the name and connect to the received IP address, where the main node was already waiting for them. </p><br><p>  Consider the following replication topology, covering three different data centers: </p><br><p><img src="https://habrastorage.org/getpro/habr/post_images/8fa/e2e/4f3/8fae2e4f382f3060b5a14ed9d80a5f67.png" alt="image"></p><br><p>  In the event of a failure of the main node, a new server should be assigned in its place (one of the replicas). </p><br><p>  <code>orchestrator</code> detects a failure, selects a new master node, and then assigns the name / VIP.  The clients do not really know the identity of the main node; they only know the name, which now must point to the new node.  However, pay attention to that. </p><br><p>  VIP-addresses are shared, the database servers request them and own them.  To receive or release a VIP, the server must send an ARP request.  The server owning the VIP must first release it before the new master has access to this address.  This approach leads to some undesirable consequences: </p><br><ul><li>  In normal mode, the failover system will first contact the failed main node and request it to release the VIP, and then contact the new main server with a request for assigning VIP.  But what to do if the first head node is unavailable or refuses to request to release the VIP address?  Given that the server is currently in a state of failure, it is unlikely that it will be able to respond to the request in a timely manner or respond to it altogether. <br><ol><li>  As a result, a situation may arise when two hosts claim their rights to the same VIP.  Different clients can connect to any of these servers, depending on the shortest network path. </li><li>  The correct operation in this situation depends on the interaction of two independent servers, and this configuration is unreliable. </li></ol></li><li>  Even if the first master node responds to requests, we are wasting precious time: switching to a new master server does not occur while we are contacting the old one. </li><li>  At the same time, even in the case of VIP reassignment, there is no guarantee that the existing client connections on the old server will be broken.  We again run the risk of being in a situation with two independent main nodes. </li></ul><br><p>  Somewhere in our environment, VIP addresses are related to physical location.  They are assigned to a switch or router.  Therefore, we can reassign the VIP address only to a server located in the same environment as the original head node.  In particular, in some cases, we will not be able to assign a VIP server in another data center and will need to make changes to the DNS. </p><br><ul><li>  It takes more time to propagate changes to the DNS.  Clients store DNS names for a pre-configured period of time.  Failure of multiple data centers involves longer downtime because it takes more time to provide all customers with information about the new main site. </li></ul><br><p>  These restrictions were enough to force us to start the search for a new solution, but it was necessary to take into account the following: </p><br><ul><li>  The main nodes independently transmitted heartbeat packets through the <code>pt-heartbeat</code> to <a href="https://githubengineering.com/mitigating-replication-lag-and-reducing-read-load-with-freno/">measure the amount of lag and adjust the load</a> .  The service needed to be transferred to the newly designated head node.  If possible, it should be disabled on the old server. </li><li>  Similarly, the main nodes independently managed the work with <a href="">Pseudo-GTID</a> .  It was necessary to start this process on the new main node and it is desirable to stop on the old one. </li><li>  A new master node became available for writing.  The old node (if possible) should have received the <code>read_only</code> label (read-only). </li></ul><br><p>  These additional steps increased total downtime and added their own points of failure and problems. </p><br><p>  The solution worked, and GitHub successfully worked out MySQL failures in the background, but we wanted to improve our approach to HA as follows: </p><br><ul><li>  ensure independence from specific data centers; </li><li>  guarantee performance in case of data center failures; </li><li>  abandon unreliable collaborative workflows; </li><li>  reduce total downtime; </li><li>  perform, as far as possible, lossless failures. </li></ul><br><h3 id="ha-reshenie-github-orchestrator-consul-glb">  GitHub HA Solution: orchestrator, Consul, GLB </h3><br><p>  Our new strategy, along with the accompanying improvements, eliminates most of the problems mentioned above or mitigates their consequences.  Our current HA system consists of the following elements: </p><br><ul><li>  <a href="https://github.com/github/orchestrator">orchestrator</a> for detecting and developing failures.  We use an <a href="">orchestrator / raft</a> scheme with multiple data centers, as shown in the figure below; </li><li>  Hashicorp <a href="https://www.consul.io/">Consul</a> for service discovery; </li><li>  <a href="https://githubengineering.com/glb-director-open-source-load-balancer/">GLB / HAProxy</a> as a proxy layer between clients and recording nodes.  <a href="https://github.com/github/glb-director">The source code</a> for the GLB Director tool is open; </li><li>  <code>anycast</code> technology for network routing. </li></ul><br><p><img src="https://habrastorage.org/getpro/habr/post_images/762/fb4/7a0/762fb47a0de253cce045889faa945228.png" alt="image"></p><br><p>  The new scheme allowed to completely abandon the changes in VIP and DNS.  Now, with the introduction of new components, we can separate them and simplify the task.  In addition, we were able to use reliable and stable solutions.  A detailed analysis of the new solution is given below. </p><br><h3 id="normalnyy-potok">  Normal flow </h3><br><p>  Normally, applications connect to write nodes via GLB / HAProxy. </p><br><p>  Applications do not receive core server credentials.  As before, they use only the name.  For example, the master node for <code>cluster1</code> would be <code>mysql-writer-1.github.net</code> .  However, in our current configuration, this name resolves to the <a href="https://en.wikipedia.org/wiki/Anycast">anycast</a> IP address. </p><br><p>  Thanks to <code>anycast</code> technology, the name is resolved to the same IP address anywhere, but traffic is sent differently, given the location of the client.  In particular, several copies of GLB, our high-availability load balancer, are deployed in each of our data centers.  Traffic to <code>mysql-writer-1.github.net</code> always directed to the GLB cluster of the local data center.  Due to this, all clients are served by local proxies. </p><br><p>  We run GLB on top of <a href="https://www.haproxy.com/">HAProxy</a> .  Our HAProxy server provides <em>write pools</em> : one for each MySQL cluster.  Moreover, each pool has only one server (the <em>main</em> cluster node).  All GLB / HAProxy instances in all data centers have the same pools, and they all point to the same servers in these pools.  Thus, if an application wants to write data to the database on <code>mysql-writer-1.github.net</code> , then it does not matter to which GLB server it is connected.  In any case, it will be redirected to the actual <code>cluster1</code> . </p><br><p>  For applications, detection ends in GLB, and there is no need for re-detection.  It is GLB that redirects traffic to the right place. </p><br><p>  Where does GLB get information about which servers to include in the list?  How do we make changes to GLB? </p><br><h3 id="obnaruzhenie-cherez-consul">  Detection via Consul </h3><br><p>  Consul is widely known as a service discovery solution; in addition, it also takes over the DNS functions.  However, in our case, we use it as a highly accessible storage of key values ‚Äã‚Äã(KV). </p><br><p>  In the KV repository in Consul, we record the identity of the main nodes of the cluster.  For each cluster there is a set of KV records pointing to the data of the corresponding main node: its <code>fqdn</code> , port, ipv4 and ipv6 addresses. </p><br><p>  Each GLB / HAProxy node runs a <a href="https://github.com/hashicorp/consul-template">consul-template</a> , a service that tracks changes in Consul data (in our case, changes in the data of the main nodes).  The <code>consul-template</code> creates a configuration file and can reload HAProxy when changing settings. </p><br><p>  Due to this, the information about changing the identity of the main node in Consul is available to each GLB / HAProxy instance.  Based on this information, instance configuration is performed, new master nodes are listed as the only entity in the cluster server pool.  After this, the instances are rebooted for the changes to take effect. </p><br><p>  We deployed Consul instances at each data center, and each instance provides high availability.  However, these instances are independent of each other.  They do not replicate or exchange any data. </p><br><p>  Where does Consul get information about changes and how does it spread between data centers? </p><br><h3 id="orchestratorraft">  orchestrator / raft </h3><br><p>  We use the <code>orchestrator/raft</code> scheme: <code>orchestrator</code> nodes interact with each other through consensus <a href="https://raft.github.io/">raft</a> .  We have one or two <code>orchestrator</code> nodes in each data center. </p><br><p>  <code>orchestrator</code> is responsible for detecting failures, working out MySQL failures, and transmitting changed data on the main node to Consul.  Failover is managed by one <code>orchestrator/raft</code> master node, but the <em>changes</em> , the news that the cluster now has a new master node, are propagated to all <code>orchestrator</code> nodes using the <code>raft</code> mechanism. </p><br><p>  When the <code>orchestrator</code> nodes receive news of changes in the main node data, each of them communicates with its local Consul instance and initiates a KV record.  A data center with multiple <code>orchestrator</code> instances will receive several (identical) entries in Consul. </p><br><h3 id="obobschennoe-predstavlenie-vsego-potoka">  A generalized view of the entire stream. </h3><br><p>  If the main node fails: </p><br><ul><li>  <code>orchestrator</code> nodes detect failures; </li><li>  The <code>orchestrator/raft</code> host initiates a restore.  A new master node is assigned; </li><li>  the <code>orchestrator/raft</code> schema transmits data on changes in the host to all nodes in the <code>raft</code> cluster; </li><li>  each <code>orchestrator/raft</code> instance receives a node change notification and writes the identification data of the new main node to the local KV storage in Consul; </li><li>  The <code>consul-template</code> service is launched on each GLB / HAProxy instance, which tracks changes to the KV repository in Consul, reconfigures and reloads HAProxy; </li><li>  client traffic is redirected to the new master node. </li></ul><br><p>  For each component, responsibilities are clearly distributed, and the whole structure is diversified and simplified.  <code>orchestrator</code> does not interact with load balancers.  Consul does not require information about the origin of information.  Proxy servers only work with Consul.  Clients work only with proxy servers. </p><br><p>  Moreover: </p><br><ul><li>  No need to make changes to the DNS and distribute information about them; </li><li>  TTL is not used; </li><li>  The thread does not wait for responses from the master in an error state.  In general, it is ignored. </li></ul><br><h3 id="dopolnitelnaya-informaciya">  Additional Information </h3><br><p>  To stabilize the flow, we also use the following methods: </p><br><ul><li>  The HAProxy <code>hard-stop-after</code> parameter is set to a very small value.  When HAProxy reboots with a new server in the write pool, the server automatically terminates all existing connections to the old master node. <br><ol><li>  Setting the <code>hard-stop-after</code> parameter allows you not to wait for any actions from clients; in addition, the negative consequences of the possible occurrence of two main nodes in a cluster are minimized.  It is important to understand that there is no magic here, and in any case <em>some time</em> passes before the old connections are broken.  But there is a moment in time after which we can stop waiting for unpleasant surprises. </li></ol></li><li>  We do not require the continued availability of the Consul service.  In fact, we need it to be available only during failover.  If the Consul service does not respond, then GLB continues to work with the latest known values ‚Äã‚Äãand does not take drastic measures. </li><li>  GLB is configured to verify the identity of the newly assigned head node.  As with our <a href="https://githubengineering.com/context-aware-mysql-pools-via-haproxy/">context-sensitive MySQL pools</a> , a check is performed to confirm that the server is truly writable.  If we accidentally delete the host identity in Consul, there will be no problem, the blank entry will be ignored.  If we mistakenly write the name of another server (not the main one) to Consul, then in this case it's okay: GLB will not update it and will continue to work with the last valid state. </li></ul><br><p>  In the following sections, we look at the problems and analyze the goals of high availability. </p><br><h3 id="obnaruzhenie-sboev-s-pomoschyu-orchestratorraft">  Crash detection with orchestrator / raft </h3><br><p>  <code>orchestrator</code> uses an <a href="">integrated approach</a> to fault detection, which ensures high reliability of the tool.  We do not face false positive results, premature failover is not performed, which means that optional downtime is excluded. </p><br><p>  The <code>orchestrator/raft</code> scheme also copes with situations of complete network isolation of the data center ("data center fencing").  Network data center isolation can be confusing: the servers inside the data center can communicate with each other.  How to understand who is really isolated - the servers <em>inside the</em> data center or all the <em>other</em> data centers? </p><br><p>  In the <code>orchestrator/raft</code> schema, the <code>orchestrator/raft</code> master node performs failover.  The host becomes the host, which receives majority support in the group (quorum).  We deployed the <code>orchestrator</code> node in such a way that no single data center can provide the majority, while any <code>n-1</code> data center provides it. </p><br><p>  In the case of a complete network isolation of the data center, <code>orchestrator</code> nodes in this center are disconnected from similar nodes in other data centers.  As a result, <code>orchestrator</code> nodes in an isolated data center cannot become leading in a <code>raft</code> cluster.  If such a node was leading, then it loses this status.  A new master will be assigned one of the nodes in the other data centers.  This presenter will have the support of all other data centers that can communicate with each other. </p><br><p>  Thus, the <code>orchestrator</code> host will always be located outside the data center isolated from the network.  If the main node was in an isolated data center, the <code>orchestrator</code> initiates failover to replace it with one of the available data centers.  We mitigate the effects of data center isolation by delegating decisions to the quorum of available data centers. </p><br><h3 id="uskorennoe-opoveschenie">  Accelerated Alert </h3><br><p>  The total idle time can be further reduced if you speed up the notification of a change in the main node.  How to achieve this? </p><br><p>  When the <code>orchestrator</code> starts failover, it considers a group of servers, one of which can be designated as the main server.  Given the replication rules, recommendations, and limitations, he is able to make an informed decision about the best course of action. </p><br><p>  By the following features, he can also understand that an accessible server is <em>an ideal candidate</em> for being the main <em>candidate</em> : </p><br><ul><li>  nothing prevents the server from raising its status (and, perhaps, the user recommends this server); </li><li>  It is expected that the server will be able to use all other servers as replicas. </li></ul><br><p>  In this case, the <code>orchestrator</code> first configures the server as writable and immediately announces an increase in its status (in our case it makes an entry in the KV repository in the Consul). –ü—Ä–∏ —ç—Ç–æ–º orchestrator –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –Ω–∞—á–∏–Ω–∞–µ—Ç –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å –¥–µ—Ä–µ–≤–æ —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏, —á—Ç–æ –æ–±—ã—á–Ω–æ –∑–∞–Ω–∏–º–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥. </p><br><p> –í–ø–æ–ª–Ω–µ –≤–µ—Ä–æ—è—Ç–Ω–æ, —á—Ç–æ –∫ —Ç–æ–º—É –≤—Ä–µ–º–µ–Ω–∏, –∫–æ–≥–¥–∞ –Ω–∞—à–∏ —Å–µ—Ä–≤–µ—Ä—ã GLB –±—É–¥—É—Ç –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω—ã, –¥–µ—Ä–µ–≤–æ —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏ —Ç–∞–∫–∂–µ –±—É–¥–µ—Ç –≥–æ—Ç–æ–≤–æ, —Ö–æ—Ç—è —ç—Ç–æ –∏ –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ. –í–æ—Ç –∏ –≤—Å–µ: —Å–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤ –∫ –∑–∞–ø–∏—Å–∏! </p><br><h3 id="polusinhronnaya-replikaciya"> –ü–æ–ª—É—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ä–µ–ø–ª–∏–∫–∞—Ü–∏—è </h3><br><p> –í –ø—Ä–æ—Ü–µ—Å—Å–µ <a href="https://dev.mysql.com/doc/refman/8.0/en/replication-semisync.html">–ø–æ–ª—É—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏</a> MySQL –≥–ª–∞–≤–Ω—ã–π —É–∑–µ–ª –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç —Ñ–∏–∫—Å–∞—Ü–∏—é —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –¥–æ —Ç–µ—Ö –ø–æ—Ä, –ø–æ–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ç–æ—á–Ω–æ –Ω–µ –±—É–¥—É—Ç –ø–µ—Ä–µ–¥–∞–Ω—ã –≤ –æ–¥–Ω—É –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–ø–ª–∏–∫. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±–µ—Å–ø–µ—á–∏—Ç—å –æ—Ç—Ä–∞–±–æ—Ç–∫—É –æ—Ç–∫–∞–∑–æ–≤ –±–µ–∑ –ø–æ—Ç–µ—Ä—å: –ª—é–±—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è, –ø—Ä–∏–º–µ–Ω–µ–Ω–Ω—ã–µ –∫ –≥–ª–∞–≤–Ω–æ–º—É —É–∑–ª—É, –ª–∏–±–æ —É–∂–µ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã, –ª–∏–±–æ –æ–∂–∏–¥–∞—é—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –∫ –æ–¥–Ω–æ–π –∏–∑ –µ–≥–æ —Ä–µ–ø–ª–∏–∫. </p><br><p> –¢–∞–∫–∞—è —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å –∏–º–µ–µ—Ç —Å–≤–æ—é —Ü–µ–Ω—É, –ø–æ—Å–∫–æ–ª—å–∫—É –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ —Å–Ω–∏–∂–µ–Ω–∏—é –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏. –ï—Å–ª–∏ –Ω–∏ –æ–¥–Ω–∞ —Ä–µ–ø–ª–∏–∫–∞ –Ω–µ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç –ø–æ–ª—É—á–µ–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –≥–ª–∞–≤–Ω—ã–π —É–∑–µ–ª –±—É–¥–µ—Ç –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω, –∞ –∑–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è. –ö —Å—á–∞—Å—Ç—å—é, –º–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è, –ø–æ –∏—Å—Ç–µ—á–µ–Ω–∏–∏ –∫–æ—Ç–æ—Ä–æ–≥–æ –≥–ª–∞–≤–Ω—ã–π —É–∑–µ–ª —Å–º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å—Å—è –≤ —Ä–µ–∂–∏–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏, –∏ –∑–∞–ø–∏—Å—å –±—É–¥–µ—Ç –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∞. </p><br><p> –ú—ã –≤—ã–±—Ä–∞–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–∏–∑–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è: <code>500 –º—Å</code> . –≠—Ç–æ–≥–æ –±–æ–ª–µ–µ —á–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Å –≥–ª–∞–≤–Ω–æ–≥–æ —É–∑–ª–∞ –≤ —Ä–µ–ø–ª–∏–∫–∏ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –¶–û–î –∏ –¥–∞–∂–µ –≤ —É–¥–∞–ª–µ–Ω–Ω—ã–µ –¶–û–î. –° —Ç–∞–∫–∏–º –≤—Ä–µ–º–µ–Ω–µ–º –æ–∂–∏–¥–∞–Ω–∏—è –º—ã –ø–æ–ª—É—á–∏–ª–∏ –∏–¥–µ–∞–ª—å–Ω—ã–π –ø–æ–ª—É—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º (–±–µ–∑ –æ—Ç–∫–∞—Ç–∞ –∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏), –∞ —Ç–∞–∫–∂–µ –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–π –ø–µ—Ä–∏–æ–¥ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –≤ —Å–ª—É—á–∞–µ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è. </p><br><p> –ú—ã –≤–∫–ª—é—á–∞–µ–º –ø–æ–ª—É—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ä–µ–ø–ª–∏–∫–∞—Ü–∏—é –Ω–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–ø–ª–∏–∫–∞—Ö –≤ –¶–û–î –∏ –≤ —Å–ª—É—á–∞–µ –≤—ã—Ö–æ–¥–∞ –∏–∑ —Å—Ç—Ä–æ—è –≥–ª–∞–≤–Ω–æ–≥–æ —É–∑–ª–∞ –æ–∂–∏–¥–∞–µ–º (—Ö–æ—Ç—è –∏ –Ω–µ —Ç—Ä–µ–±—É–µ–º) –æ—Ç—Ä–∞–±–æ—Ç–∫—É –æ—Ç–∫–∞–∑–∞ –±–µ–∑ –ø–æ—Ç–µ—Ä—å. –û—Ç—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–∫–∞–∑–∞ –±–µ–∑ –ø–æ—Ç–µ—Ä—å –ø—Ä–∏ –ø–æ–ª–Ω–æ–º –æ—Ç–∫–∞–∑–µ –¶–û–î –æ–±—Ö–æ–¥–∏—Ç—Å—è —Å–ª–∏—à–∫–æ–º –¥–æ—Ä–æ–≥–æ, –ø–æ—ç—Ç–æ–º—É –º—ã —ç—Ç–æ–≥–æ –∏ –Ω–µ –∂–¥–µ–º. </p><br><p> –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É—è —Å–æ –≤—Ä–µ–º–µ–Ω–µ–º –æ–∂–∏–¥–∞–Ω–∏—è –¥–ª—è –ø–æ–ª—É—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏, –º—ã —Ç–∞–∫–∂–µ –æ–±–Ω–∞—Ä—É–∂–∏–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ –≤—ã–±–æ—Ä <em>–∏–¥–µ–∞–ª—å–Ω–æ–≥–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞</em> –≤ —Å–ª—É—á–∞–µ —Å–±–æ—è –≥–ª–∞–≤–Ω–æ–≥–æ —É–∑–ª–∞. –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–≤ –ø–æ–ª—É—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º –Ω–∞ –Ω—É–∂–Ω—ã—Ö —Å–µ—Ä–≤–µ—Ä–∞—Ö –∏ –ø–æ–º–µ—Ç–∏–≤ –∏—Ö –≤ –∫–∞—á–µ—Å—Ç–≤–µ <em>–∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤</em> , –º—ã –º–æ–∂–µ–º —É–º–µ–Ω—å—à–∏—Ç—å –æ–±—â–µ–µ –≤—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è, –ø–æ—Å–∫–æ–ª—å–∫—É <em>–≤–ª–∏—è–µ–º</em> –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ç—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–∫–∞–∑–∞. –ù–∞—à–∏ <a href="https://githubengineering.com/mysql-testing-automation-at-github/">—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã</a> –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç, —á—Ç–æ –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤ –º—ã –ø–æ–ª—É—á–∞–µ–º <em>–∏–¥–µ–∞–ª—å–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤</em> –∏, —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –±—ã—Å—Ç—Ä–µ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–º–µ–Ω–µ –≥–ª–∞–≤–Ω–æ–≥–æ —É–∑–ª–∞. </p><br><h3 id="peredacha-paketov-pulsa"> –ü–µ—Ä–µ–¥–∞—á–∞ –ø–∞–∫–µ—Ç–æ–≤ –ø—É–ª—å—Å–∞ </h3><br><p> –í–º–µ—Å—Ç–æ —Ç–æ–≥–æ, —á—Ç–æ–±—ã —É–ø—Ä–∞–≤–ª—è—Ç—å –∑–∞–ø—É—Å–∫–æ–º/–æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π —Å–ª—É–∂–±—ã <code>pt-heartbeat</code> –Ω–∞ –Ω–∞–∑–Ω–∞—á–∞–µ–º—ã—Ö/–æ—Ç–∫–ª—é—á–∞–µ–º—ã—Ö –≥–ª–∞–≤–Ω—ã—Ö —É–∑–ª–∞—Ö, –º—ã —Ä–µ—à–∏–ª–∏ –∑–∞–ø—É—Å–∫–∞—Ç—å –µ–µ –≤–µ–∑–¥–µ –∏ –≤—Å–µ–≥–¥–∞. –≠—Ç–æ –ø–æ—Ç—Ä–µ–±–æ–≤–∞–ª–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π <a href="https://github.com/percona/percona-toolkit/pull/302/files%3Fw%3D1">–¥–æ—Ä–∞–±–æ—Ç–∫–∏</a> , —á—Ç–æ–±—ã —Å–ª—É–∂–±–∞ <code>pt-heartbeat</code> –º–æ–≥–ª–∞ —Å–ø–æ–∫–æ–π–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Å–µ—Ä–≤–µ—Ä–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ –ª–∏–±–æ —á–∞—Å—Ç–æ –∏–∑–º–µ–Ω—è—é—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ <code>read_only</code> , –ª–∏–±–æ —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. </p><br><p> –í –Ω–∞—à–µ–π —Ç–µ–∫—É—â–µ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å–ª—É–∂–±—ã <code>pt-heartbeat</code> —Ä–∞–±–æ—Ç–∞—é—Ç –∫–∞–∫ –Ω–∞ –≥–ª–∞–≤–Ω—ã—Ö —É–∑–ª–∞—Ö, —Ç–∞–∫ –∏ –Ω–∞ –∏—Ö —Ä–µ–ø–ª–∏–∫–∞—Ö. –ù–∞ –≥–ª–∞–≤–Ω—ã—Ö —É–∑–ª–∞—Ö –æ–Ω–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç —Å–æ–±—ã—Ç–∏—è –ø—É–ª—å—Å–∞. –ù–∞ —Ä–µ–ø–ª–∏–∫–∞—Ö –æ–Ω–∏ –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å —Å–µ—Ä–≤–µ—Ä–æ–≤ —Ç–æ–ª—å–∫–æ –¥–ª—è —á—Ç–µ–Ω–∏—è –∏ —Ä–µ–≥—É–ª—è—Ä–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—é—Ç –∏—Ö —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ. –ö–∞–∫ —Ç–æ–ª—å–∫–æ —Å–µ—Ä–≤–µ—Ä —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –≥–ª–∞–≤–Ω—ã–º, —Å–ª—É–∂–±–∞ <code>pt-heartbeat</code> –Ω–∞ —ç—Ç–æ–º —Å–µ—Ä–≤–µ—Ä–µ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –µ–≥–æ –∫–∞–∫ –¥–æ—Å—Ç—É–ø–Ω—ã–π –¥–ª—è –∑–∞–ø–∏—Å–∏ –∏ –Ω–∞—á–∏–Ω–∞–µ—Ç –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏—è –ø—É–ª—å—Å–∞. </p><br><h3 id="delegirovanie-zadach-orchestrator"> –î–µ–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á orchestrator </h3><br><p> –ú—ã —Ç–∞–∫–∂–µ –¥–µ–ª–µ–≥–∏—Ä–æ–≤–∞–ª–∏ orchestrator —Å–ª–µ–¥—É—é—â–∏–µ –∑–∞–¥–∞—á–∏: </p><br><ul><li> –≥–µ–Ω–µ—Ä–∞—Ü–∏—è Pseudo-GTID; </li><li> –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–æ–≤–æ–≥–æ –º–∞—Å—Ç–µ—Ä–∞ –∫–∞–∫ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ –¥–ª—è –∑–∞–ø–∏—Å–∏, –æ—á–∏—Å—Ç–∫–∞ –µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Ä–µ–ø–ª–∏–∫–∞—Ü–∏–∏; </li><li> –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ç–∞—Ä–æ–≥–æ –º–∞—Å—Ç–µ—Ä–∞ –∫–∞–∫ –¥–æ—Å—Ç—É–ø–Ω–æ–≥–æ —Ç–æ–ª—å–∫–æ –¥–ª—è —á—Ç–µ–Ω–∏—è ( <code>read_only</code> ), –µ—Å–ª–∏ —ç—Ç–æ –≤–æ–∑–º–æ–∂–Ω–æ. </li></ul><br><p> –≠—Ç–æ —É–ø—Ä–æ—â–∞–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–¥–∞—á, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å –Ω–æ–≤—ã–º –≥–ª–∞–≤–Ω—ã–º —É–∑–ª–æ–º. –£–∑–µ–ª, –∫–æ—Ç–æ—Ä—ã–π —Ç–æ–ª—å–∫–æ —á—Ç–æ –±—ã–ª –Ω–∞–∑–Ω–∞—á–µ–Ω –≥–ª–∞–≤–Ω—ã–º, —è–≤–Ω–æ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω—ã–º –∏ –¥–æ—Å—Ç—É–ø–Ω—ã–º, –∏–Ω–∞—á–µ –º—ã –±—ã –µ–≥–æ –Ω–µ –Ω–∞–∑–Ω–∞—á–∏–ª–∏. –ü–æ—ç—Ç–æ–º—É –∏–º–µ–µ—Ç —Å–º—ã—Å–ª –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å <code>orchestrator</code> –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–º–µ–Ω—è—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–µ–ø–æ—Å—Ä–µ–¥—Å—Ç–≤–µ–Ω–Ω–æ –Ω–∞ –≤–Ω–æ–≤—å –Ω–∞–∑–Ω–∞—á–µ–Ω–Ω–æ–º –≥–ª–∞–≤–Ω–æ–º —É–∑–ª–µ. </p><br><h3 id="ogranicheniya-i-nedostatki"> –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∏ </h3><br><p> –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–∫—Å–∏-—Å–ª–æ—è –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ —Ç–æ–º—É, —á—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –Ω–µ –ø–æ–ª—É—á–∞—é—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≥–ª–∞–≤–Ω–æ–≥–æ —É–∑–ª–∞, –æ–¥–Ω–∞–∫–æ –∏ —Å–∞–º —ç—Ç–æ—Ç —É–∑–µ–ª –Ω–µ –º–æ–∂–µ—Ç –∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è. –ì–ª–∞–≤–Ω–æ–º—É —É–∑–ª—É –¥–æ—Å—Ç—É–ø–Ω—ã —Ç–æ–ª—å–∫–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è, –ø–æ—Å—Ç—É–ø–∞—é—â–∏–µ –∏–∑ –ø—Ä–æ–∫—Å–∏-—Å–ª–æ—è, –∏ –º—ã —Ç–µ—Ä—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–µ–∞–ª—å–Ω–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–µ —ç—Ç–∏—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π. </p><br><p> –í –ø–ª–∞–Ω–µ —Ä–∞–∑–≤–∏—Ç–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —Å–∏—Å—Ç–µ–º, —É –Ω–∞—Å –≤—Å–µ –µ—â–µ –µ—Å—Ç—å –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏. </p><br><p> –û—Ç–º–µ—Ç–∏–º, —á—Ç–æ –ø—Ä–∏ –∏–∑–æ–ª—è—Ü–∏–∏ —Ü–µ–Ω—Ç—Ä–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, –≤ –∫–æ—Ç–æ—Ä–æ–º –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≥–ª–∞–≤–Ω—ã–π —É–∑–µ–ª, –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –≤ —ç—Ç–æ–º –¶–û–î –ø–æ-–ø—Ä–µ–∂–Ω–µ–º—É –º–æ–≥—É—Ç –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å –∑–∞–ø–∏—Å—å –Ω–∞ —Ç–∞–∫–æ–π —É–∑–µ–ª. –≠—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –Ω–µ—Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç–∏ —Å–æ—Å—Ç–æ—è–Ω–∏–π –ø–æ—Å–ª–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è —Å–µ—Ç–∏. –ú—ã —Å—Ç–∞—Ä–∞–µ–º—Å—è —Å–º—è–≥—á–∏—Ç—å –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è –¥–≤—É—Ö –≥–ª–∞–≤–Ω—ã—Ö —É–∑–ª–æ–≤ –≤ —Ç–∞–∫–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏ –ø—É—Ç–µ–º —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –º–µ—Ç–æ–¥–∞ <a href="https://en.wikipedia.org/wiki/STONITH">STONITH</a> –∏–∑–Ω—É—Ç—Ä–∏ —Å–∞–º–æ–≥–æ –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¶–û–î. –ö–∞–∫ —É–∂–µ –≥–æ–≤–æ—Ä–∏–ª–æ—Å—å —Ä–∞–Ω–µ–µ, –ø—Ä–æ–π–¥–µ—Ç <em>–Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è</em> , –ø—Ä–µ–∂–¥–µ —á–µ–º —Å—Ç–∞—Ä—ã–π –≥–ª–∞–≤–Ω—ã–π —É–∑–µ–ª –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á–µ–Ω, –ø–æ—ç—Ç–æ–º—É –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ ¬´–¥–≤–æ–µ–≤–ª–∞—Å—Ç–∏—è¬ª –≤—Å–µ-—Ç–∞–∫–∏ –∏–∑–±–µ–∂–∞—Ç—å –Ω–µ —É–¥–∞—Å—Ç—Å—è. –≠–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏–æ–Ω–Ω—ã–µ –∏–∑–¥–µ—Ä–∂–∫–∏, –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –Ω–∞ –ø–æ–ª–Ω–æ–µ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏—è —Ç–∞–∫–∏—Ö —Å–∏—Ç—É–∞—Ü–∏–π, –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏. </p><br><p> –°—É—â–µ—Å—Ç–≤—É—é—Ç –∏ –¥—Ä—É–≥–∏–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏: –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ Consul –≤–æ –≤—Ä–µ–º—è –æ—Ç—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–∫–∞–∑–∞, —á–∞—Å—Ç–∏—á–Ω–∞—è –∏–∑–æ–ª—è—Ü–∏—è –¶–û–î –∏ —Ç. –¥. –ú—ã –ø–æ–Ω–∏–º–∞–µ–º, —á—Ç–æ, —Ä–∞–±–æ—Ç–∞—è —Å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏ —Ç–∞–∫–æ–≥–æ —Ä–æ–¥–∞, –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ –∑–∞–∫—Ä—ã—Ç—å –≤—Å–µ –¥—ã—Ä—ã, –ø–æ—ç—Ç–æ–º—É –º—ã –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∏—Ä—É–µ–º—Å—è –Ω–∞ —Å–∞–º—ã—Ö –≤–∞–∂–Ω—ã—Ö. </p><br><h3 id="rezultaty">  results </h3><br><p> –ù–∞—à–∞ —Å–∏—Å—Ç–µ–º–∞ orchestrator/GLB/Consul –æ–±–µ—Å–ø–µ—á–∏–ª–∞ —Å–ª–µ–¥—É—é—â–∏–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: </p><br><ul><li> –Ω–∞–¥–µ–∂–Ω–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ—Ç–∫–∞–∑–æ–≤; </li><li> –æ—Ç—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–∫–∞–∑–æ–≤ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¶–û–î; </li><li> –æ—Ç—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–∫–∞–∑–æ–≤ –±–µ–∑ –ø–æ—Ç–µ—Ä—å –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤; </li><li> –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Å–µ—Ç–µ–≤–æ–π –∏–∑–æ–ª—è—Ü–∏–∏ –¶–û–î; </li><li> —Å–º—è–≥—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–π, –∫–æ–≥–¥–∞ –≤–æ–∑–Ω–∏–∫–∞—é—Ç –¥–≤–∞ –≥–ª–∞–≤–Ω—ã—Ö —É–∑–ª–∞ (—Ä–∞–±–æ—Ç–∞ –≤ —ç—Ç–æ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è); </li><li> –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π; </li><li> –æ–±—â–µ–µ –≤—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è <code>10-13 —Å–µ–∫—É–Ω–¥</code> –≤ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–µ —Å–ª—É—á–∞–µ–≤. <br><ol><li> –í —Ä–µ–¥–∫–∏—Ö —Å–∏—Ç—É–∞—Ü–∏—è—Ö –æ–±—â–µ–µ –≤—Ä–µ–º—è –ø—Ä–æ—Å—Ç–æ—è –¥–æ—Å—Ç–∏–≥–∞–µ—Ç <code>20 —Å–µ–∫—É–Ω–¥</code> , –∞ –≤ —Å–∞–º—ã—Ö –∫—Ä–∞–π–Ω–∏—Ö —Å–ª—É—á–∞—è—Ö ‚Äî <code>25 —Å–µ–∫—É–Ω–¥</code> . </li></ol></li></ul><br><h3 id="zaklyuchenie">  Conclusion </h3><br><p> –°—Ö–µ–º–∞ ¬´–æ—Ä–∫–µ—Å—Ç—Ä–æ–≤–∫–∞/–ø—Ä–æ–∫—Å–∏/–æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–ª—É–∂–±¬ª –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ö–æ—Ä–æ—à–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∏ –Ω–∞–¥–µ–∂–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –≤ –Ω–µ—Å–≤—è–∑–∞–Ω–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ, —á—Ç–æ —É–ø—Ä–æ—â–∞–µ—Ç —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ, —ç–∫—Å–ø–ª—É–∞—Ç–∞—Ü–∏—é –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥. –ü—Ä–∏ —ç—Ç–æ–º –∫–∞–∂–¥—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –º–æ–∂–Ω–æ –æ—Ç–¥–µ–ª—å–Ω–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞—Ç—å. –ú—ã –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏—Å–∫–∞—Ç—å —Å–ø–æ—Å–æ–±—ã —É–ª—É—á—à–µ–Ω–∏—è, –ø–æ—Å—Ç–æ—è–Ω–Ω–æ —Ç–µ—Å—Ç–∏—Ä—É—è –Ω–∞—à—É —Å–∏—Å—Ç–µ–º—É. </p></div><p>Source: <a href="https://habr.com/ru/post/432088/">https://habr.com/ru/post/432088/</a></p>
<section class="navigation-panel">
<h4>More articles:</h4>
<nav class="list-of-articles-container js-list-of-articles-container"><p>Waiting for the list form <a href="../../index.html">here</a>...</p></nav>
</section>
<script src="../../js/main.js"></script>

<!-- Yandex.Metrika counter -->
<script type="text/javascript" >
  (function (d, w, c) {
      (w[c] = w[c] || []).push(function() {
          try {
              w.yaCounter52496797 = new Ya.Metrika({
                  id:52496797,
                  clickmap:true,
                  trackLinks:true,
                  accurateTrackBounce:true,
                  webvisor:true
              });
          } catch(e) { }
      });

      var n = d.getElementsByTagName("script")[0],
          s = d.createElement("script"),
          f = function () { n.parentNode.insertBefore(s, n); };
      s.type = "text/javascript";
      s.async = true;
      s.src = "https://mc.yandex.ru/metrika/watch.js";

      if (w.opera == "[object Opera]") {
          d.addEventListener("DOMContentLoaded", f, false);
      } else { f(); }
  })(document, window, "yandex_metrika_callbacks");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/52496797" style="position:absolute; left:-9999px;" alt="" /></div></noscript>

<!-- Google Analytics -->
  <script>
    window.ga = function () { ga.q.push(arguments) }; ga.q = []; ga.l = +new Date;
    ga('create', 'UA-134931760-1', 'auto'); ga('send', 'pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>

</section>
</body>

</html>